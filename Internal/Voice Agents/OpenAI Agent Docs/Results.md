---
title: "Results"
source: "https://openai.github.io/openai-agents-js/guides/results/"
author:
  - "[[OpenAI Agents SDK]]"
published:
created: 2025-09-06
description: "Learn how to access the results and output from your agent run"
tags:
  - "clippings"
---
[Skip to content](https://openai.github.io/openai-agents-js/guides/results/#_top)

When you [run your agent](https://openai.github.io/openai-agents-js/guides/running-agents), you will either receive a:

- [`RunResult`](https://openai.github.io/openai-agents-js/openai/agents/classes/runresult) if you call `run` without `stream: true`
- [`StreamedRunResult`](https://openai.github.io/openai-agents-js/openai/agents/classes/streamedrunresult) if you call `run` with `stream: true`. For details on streaming, also check the [streaming guide](https://openai.github.io/openai-agents-js/guides/streaming).

The `finalOutput` property contains the final output of the last agent that ran. This result is either:

- `string` — default for any agent that has no `outputType` defined
- `unknown` — if the agent has a JSON schema defined as output type. In this case the JSON was parsed but you still have to verify its type manually.
- `z.infer<outputType>` — if the agent has a Zod schema defined as output type. The output will automatically be parsed against this schema.
- `undefined` — if the agent did not produce an output (for example stopped before it could produce an output)

If you are using handoffs with different output types, you should use the `Agent.create()` method instead of the `new Agent()` constructor to create your agents.

This will enable the SDK to infer the output types across all possible handoffs and provide a union type for the `finalOutput` property.

For example:

```typescript
import { Agent, run } from '@openai/agents';
import { z } from 'zod';

const refundAgent = new Agent({
  name: 'Refund Agent',
  instructions:
    'You are a refund agent. You are responsible for refunding customers.',
  outputType: z.object({
    refundApproved: z.boolean(),
  }),
});

const orderAgent = new Agent({
  name: 'Order Agent',
  instructions:
    'You are an order agent. You are responsible for processing orders.',
  outputType: z.object({
    orderId: z.string(),
  }),
});

const triageAgent = Agent.create({
  name: 'Triage Agent',
  instructions:
    'You are a triage agent. You are responsible for triaging customer issues.',
  handoffs: [refundAgent, orderAgent],
});

const result = await run(triageAgent, 'I need to a refund for my order');

const output = result.finalOutput;
// ^? { refundApproved: boolean } | { orderId: string } | string | undefined
```

There are two ways you can access the inputs for your next turn:

- `result.history` — contains a copy of both your input and the output of the agents.
- `result.output` — contains the output of the full agent run.

`history` is a convenient way to maintain a full history in a chat-like use case:

```typescript
import { AgentInputItem, Agent, user, run } from '@openai/agents';

const agent = new Agent({
  name: 'Assistant',
  instructions:
    'You are a helpful assistant knowledgeable about recent AGI research.',
});

let history: AgentInputItem[] = [
  // initial message
  user('Are we there yet?'),
];

for (let i = 0; i < 10; i++) {
  // run 10 times
  const result = await run(agent, history);

  // update the history to the new output
  history = result.history;

  history.push(user('How about now?'));
}
```

The `lastAgent` property contains the last agent that ran. Depending on your application, this is often useful for the next time the user inputs something. For example, if you have a frontline triage agent that hands off to a language-specific agent, you can store the last agent, and reuse it the next time the user messages the agent.

In streaming mode it can also be useful to access the `currentAgent` property that’s mapping to the current agent that is running.

The `newItems` property contains the new items generated during the run. The items are [`RunItem`](https://openai.github.io/openai-agents-js/openai/agents/type-aliases/runitem) s. A run item wraps the raw item generated by the LLM. These can be used to access additionally to the output of the LLM which agent these events were associated with.

- [`RunMessageOutputItem`](https://openai.github.io/openai-agents-js/openai/agents/classes/runmessageoutputitem) indicates a message from the LLM. The raw item is the message generated.
- [`RunHandoffCallItem`](https://openai.github.io/openai-agents-js/openai/agents/classes/runhandoffcallitem) indicates that the LLM called the handoff tool. The raw item is the tool call item from the LLM.
- [`RunHandoffOutputItem`](https://openai.github.io/openai-agents-js/openai/agents/classes/runhandoffoutputitem) indicates that a handoff occurred. The raw item is the tool response to the handoff tool call. You can also access the source/target agents from the item.
- [`RunToolCallItem`](https://openai.github.io/openai-agents-js/openai/agents/classes/runtoolcallitem) indicates that the LLM invoked a tool.
- [`RunToolCallOutputItem`](https://openai.github.io/openai-agents-js/openai/agents/classes/runtoolcalloutputitem) indicates that a tool was called. The raw item is the tool response. You can also access the tool output from the item.
- [`RunReasoningItem`](https://openai.github.io/openai-agents-js/openai/agents/classes/runreasoningitem) indicates a reasoning item from the LLM. The raw item is the reasoning generated.
- [`RunToolApprovalItem`](https://openai.github.io/openai-agents-js/openai/agents/classes/runtoolapprovalitem) indicates that the LLM requested approval for a tool call. The raw item is the tool call item from the LLM.

The `state` property contains the state of the run. Most of what is attached to the `result` is derived from the `state` but the `state` is serializable/deserializable and can also be used as input for a subsequent call to `run` in case you need to [recover from an error](https://openai.github.io/openai-agents-js/guides/running-agents#exceptions) or deal with an [`interruption`](https://openai.github.io/openai-agents-js/guides/results/#interruptions).

If you are using `needsApproval` in your agent, your `run` might trigger some `interruptions` that you need to handle before continuing. In that case `interruptions` will be an array of `ToolApprovalItem` s that caused the interruption. Check out the [human-in-the-loop guide](https://openai.github.io/openai-agents-js/guides/human-in-the-loop) for more information on how to work with interruptions.

The `rawResponses` property contains the raw LLM responses generated by the model during the agent run.

The `lastResponseId` property contains the ID of the last response generated by the model during the agent run.

The `inputGuardrailResults` and `outputGuardrailResults` properties contain the results of the guardrails, if any. Guardrail results can sometimes contain useful information you want to log or store, so we make these available to you.

The `input` property contains the original input you provided to the run method. In most cases you won’t need this, but it’s available in case you do.